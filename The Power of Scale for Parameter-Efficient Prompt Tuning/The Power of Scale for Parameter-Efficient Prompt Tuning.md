# The Power of Scale for Parameter-Efficient Prompt Tuning
## 摘要
在这项工作中，我们探索了“提示调整”，这是一种简单而有效的机制，用于学习“软提示”来调节冻结的语言模型以执行特定的下游任务。与 GPT-3 使用的离散文本提示不同，软提示是通过反向传播学习的，并且可以调整以合并来自任意数量的标记示例的信号。我们的端到端学习方法大大优于 GPT-3 的小样本学习方法。更值得注意的是，通过使用 T5 对模型大小进行消融，我们表明Prompt Tuning在规模上变得更具竞争力：随着模型超过数十亿个参数，我们的方法“缩小了差距”并匹配了模型调优的强大性能（其中所有模型权重都被进行了调整）。这一发现尤其重要，因为大型模型的共享和服务成本很高，并且为多个下游任务重用一个冻结模型的能力可以减轻这种负担。我们的方法可以看作是 Li 和 Liang (2021) 最近提出的“前缀调整”的简化，我们提供了与此方法和其他类似方法的比较。最后，我们展示了使用软提示对冻结模型进行调节可以提高域迁移的鲁棒性，并实现高效的“提示集成”。
## 介绍
随着预训练大型语言模型的广泛成功，出现了一系列技术来使这些通用模型适应下游任务。 ELMo (Peters et al., 2018) 提出冻结预训练模型并学习其每层表示的特定任务权重。 然而，自 GPT (Radford et al., 2018) 和 BERT (Devlin et al., 2019) 以来，主要的适应技术一直是模型调整（或“微调”），其中所有模型参数在适应过程中进行调整，如 霍华德和罗德 (2018) 提出。

最近，布朗等人 (2020) 表明，提示设计Prompt Design（或“priming”）在通过文本提示调节冻结的 GPT-3 模型的行为方面非常有效。 提示通常由任务描述和/或几个规范示例组成。 这种“冻结”预训练模型的回归很有吸引力，尤其是随着模型大小的不断增加，无需为每个下游任务提供单独的模型副本，单个通用模型可以同时服务于许多不同的任务。

不幸的是，基于提示的适应有几个关键的缺点。 任务描述容易出错并且需要人工参与，提示的有效性受限于模型输入可以容纳多少条件文本。 结果，下游任务质量仍然远远落后于fine-tune后的模型。 例如，尽管使用了 16 倍以上的参数，但 GPT-3 175B 在 SuperGLUE 上的少镜头性能是低微调 T5-XXL（Raffel 等人，2020）（71.8 对 89.3）的 17.5 分。

最近提出了一些自动化即时设计的努力。 申等人（2020）在下游应用程序训练数据的指导下，提出了一种在单词离散空间上的搜索算法。 虽然这种技术优于手动提示设计，但与模型调整仍有差距。

Li 和 Liang (2021) 提出了“前缀调优”，并在生成任务上显示出强大的结果。 此方法冻结模型参数并在调整期间将错误反向传播到编码器堆栈中每个层（包括输入层）的前缀激活。 Hambardzumyan 等人 （2021 年）通过将可训练参数限制在掩码语言模型的输入和输出子网络中来简化此方法，并在分类任务上显示合理的结果。

在本文中，我们建议快速调整作为适应语言模型的进一步简化。 **我们冻结了整个预训练模型，并且只允许每个下游任务额外的 k 个可调标记添加到输入文本中。 这种“软提示”是端到端训练的，可以从完整标记的数据集中压缩信号，使我们的方法优于小样本提示，并通过模型调整缩小质量差距。 同时，由于单个预训练模型被回收用于所有下游任务，我们保留了冻结模型的高效服务优势。**

虽然我们与 Li 和 Liang (2021) 以及 Hambardzumyan 等人同时开发了我们的方法。 （2021 年），**我们是第一个证明仅提示调整（没有中间层前缀或特定于任务的输出层）足以与模型调整竞争的人**。 通过第 2-3 节中的详细实验，我们证明语言模型能力是这些方法成功的关键因素。 如图 1 所示，随着规模的扩大，即时调优变得更具竞争力。

![Alt text](image.png)
![Alt text](image-1.png)

我们在第 4 节中与类似方法进行了比较。明确地将任务特定参数与一般语言理解所需的“通才”参数分开有一系列额外的好处。我们在第 5 节中展示，通过在提示中捕获任务定义，同时保持通才参数固定，我们能够获得更好的域转移弹性。在第 6 节中，我们展示了 “提示集成”Prompt Ensembling，即为同一任务学习多个提示，可以提高质量并且比经典模型集成更有效。最后，在第 7 节中，我们研究了学习到的软提示的可解释性。总之，**我们的主要贡献是： 1. 提出了快速调优，并在大型语言模型体系中展示了其与模型调优的竞争力。 2. 消融许多设计选择，显示质量和稳健性随着规模的增长而提高。 3. 在域转移问题上显示快速调优优于模型调优。 4. 提出“即兴合奏”并显示其有效性。**

## 介绍总结
提出预训练大NLP模型参数调优的Prompt Tuning方法，该方法可以不需要针对不同的下游任务对整个预训练模型进行微调，而只需要学习Prompt部分参数即可，主要是针对T5模型进行研究。

具体方法是，设计一种前缀prompt方法，在输入词嵌入之前添加前缀prompt，这一prompt并非来自人工标注，而是交由深度神经网络表示，在微调的时候，固定上游模型的参数，只微调prompt的参数，相当于对每一个下游任务，只需要额外训练一个独立的prompt参数即可。

###  Prompt介绍
Prompt是一种通过为文本任务添加提示信息，降低模型在下游任务上微调难度的方法，prompt既可以作为前缀添加在文本开头，也可以像做完形填空一样，插入在文本中间任意位置。同时，根据prompt的构造模式，可以分为Discrete prompt和Soft/continuous prompts两种。

###  Discrete prompt
Discrete prompt更多是通过先验知识来添加prompt，比如通过人类手工设计，将pretraining的只是和dowm stream的任务结合起来；另一种则是通过从trigger（触发） token的方法，这种方法假设所有的先验知识都存在于pretraining的模型之中，然后，设计某种trigger方法在下游任务中将prompt提取出来。

trigger tokens的方法可能比人类设计的思想更符合模型的学习认知。

### Soft/continuous prompts
前两种方法都是采用一定手段，人为设计或寻找prompt，其中trigger tokens方法已经可以根据设计准则自动生成prompt了，而Soft/continuous prompts更进一步，直接将prompt由参数化的模型进行估计。有些方法将prompt作为mask，将任务转换为估计这个mask的class logits的分类任务，有的则是将prompt简单地作为前缀，来做文本生成任务。

而在prompt时，也存在同时更新prompts参数和预训练模型参数，以及只更新prompts参数两种策略。

### T5 模型和Span Corruption介绍
T5( Transfer Text-to-Text Transformer)模型是一个在大规模数据集上训练的text to text模型，其网络是一种基于transformer的encoder-decoder架构，而训练方法则是近似bert风格的mask结构，称为Span Corruption。

所谓Span Corruption，其实是对输入文本进行部分mask，相当于说为文本添加了哨兵（sentinel token），然后模型的预测目标则是对这些哨兵占据的字段进行恢复，同时，其输出也同样会存在哨兵：

比如文本为：“Thank you for inviting me to your party last week”，

输入为：“Thank you me to your party week”，

期望的输出则是：“ for inviting last ”。

## Prompt Tuning

遵循 T5 的“文本到文本”方法（Raffel 等人，2020），我们将所有任务都转换为文本生成。 传统的方法一般将模型分类建模成根据输入的输出类别概率 Pr(y|X)，其中 X是一个token的序列，而 Y 是单个class的标号。而T5提出的文本到文本方法，将分类问题建模为一个条件生成问题，使用概率 Prθ(y|X)来计算生成的标号。其中，Y代表一个class label的token序列，θ代表一个由encoder和decoder决定的参数。

Prompting的本质是往模型增加一些额外的信息，使得它在生成Y的时候能够获得一些“条件”（例如“分类”）。一般来说，Prompting通过往输入X前加入一串token P 来完成，从而使得模型能够最大化得到正确的Y的可能性。注意，Prompting并不改变参数θ，也就是不改变被冻结模型的任何参数。

在GPT-3中，Prompt Token P={p1,p2,...pn}是模型的嵌入表(Embedding Table)的一部分，因此受模型的冻结参数 θ 决定。由于参数是冻结的，找最优的Prompt一般需要人为搜索或者使用不可微自动化搜索方法。Prompt Tuning消除了提示 P 由 θ 参数化的限制； 相反，Prompt Tuning中的Prompt有自己的专用参数 θp，可以通过反向传播算法更新。 Prompt Design可以看做从冻结嵌入的固定词汇表中选择Prompt Token，而Prompt Tuning可以看做token已经确定，但是embedding是可以学习的。如此一来，我们新的条件生成问题的概率就成为了 Prθ,θp(Y|[P;X])
 ，而且可以使用反向传播算法最大化 Y 的置信度，而且这是通过更新一个很小的参数 θP来实现的。

通过人为输入一串长度为n 的token序列 {x1,x2,...xn} ，T5首先会将这些token进行嵌入，获得一个嵌入表 Xe，其中e为嵌入空间的维度。在应用这个嵌入表后，我们会得到一个soft prompt的表示 Pe，其中p是prompt的长度。接下来，我们将prompt concat到输入的前面，就能得到完整的输入 [Pe;Xe]。这个新的输入将会进入T5的encoder-decoder结构来训练和推理。注意，只有 Pe在encoder-decoder结构中被被学习了。
### 设计中的一些决定
有许多可能的方法来初始化提示表示。 最简单的是从头开始训练，使用随机初始化。 一个更复杂的选项是将每个提示标记初始化为从模型词汇表中提取的嵌入。 从概念上讲，我们的软提示以与输入之前的文本相同的方式调节冻结网络的行为，因此类似单词的表示可以作为一个很好的初始化点。 对于分类任务，第三种选择是使用枚举输出类的嵌入来初始化提示，类似于 Schick 和 Schütze (2021) 的“verbalizers”。 由于我们希望模型在输出中生成这些标记，因此使用有效目标标记的嵌入初始化提示应该启动模型以将其输出限制为合法的输出类。

另一个设计考虑因素是提示的长度。 我们方法的参数成本是 EP，其中 E 是token嵌入维度，P 是提示长度。 提示越短，必须调整的新参数就越少，因此我们的目标是找到仍然表现良好的最小长度。
### Unlearning Span的损坏
与 GPT-3 等自回归语言模型不同，我们试验的 T5 模型使用编码器解码器架构并在跨度损坏目标上进行预训练。 具体来说，T5 的任务是“重建”输入文本中的掩码跨度，这些跨度用唯一的哨兵标记进行标记。 目标输出文本由所有被屏蔽的内容组成，由标记分隔，加上一个最终标记。 例如，从文本““Thank you for inviting me to your party last week”，我们可以构建一个预训练示例，其中输入是“Thank you <X> me to your party <Y> week”，目标输出是““<X> for inviting <Y> last <Z>”。

虽然拉斐尔等人 (2020) 发现这种架构和预训练目标比传统语言建模更有效，我们假设这种设置不适合生成可以通过快速调整轻松控制的冻结模型。 特别是，专门针对span损坏进行预训练的 T5 模型，例如 T5.1.1，从未见过真正自然的输入文本（没有哨兵标记），也从未被要求预测真正的自然目标。 事实上，由于 T5 的跨度损坏预处理的细节，每个预训练目标都会以一个哨兵开始。 虽然这种输出哨兵的“不自然”倾向很容易通过微调来克服，但我们怀疑仅通过提示来覆盖会更加困难，因为无法调整解码器的先验。

考虑到这些问题，我们在三种设置中试验了 T5 模型。 (1) “Span Corruption”：我们使用预训练的现成 T5 作为我们的冻结模型，并测试其为下游任务输出预期文本的能力。 (2) “Span Corruption + Sentinel”：我们使用相同的模型，但在所有下游目标前面加上一个哨兵，以便更接近预训练中看到的目标。 (3) “LM Adaptation”：我们继续 T5 的自我监督训练，进行少量额外步骤，但使用 Raffel 等人讨论的“LM”目标。 （2020）； 给定自然文本前缀作为输入，模型必须生成自然文本延续作为输出。 至关重要的是，这种适应只发生一次，产生一个单一的冻结模型，我们可以重用该模型，以便在任意数量的下游任务中进行快速调整。

通过 LM 适配，我们希望将 T5 “快速”转化为更类似于 GPT-3 的模型，该模型始终输出逼真的文本，并且以“few-shot learner”的身份对提示反应良好而著称。 与从头开始的预训练相比，这种后期转换的成功程度尚不清楚，而且据我们所知，以前也没有对此进行过调查。 因此，我们尝试了长达 100K 步的各种适应长度。

##  Prompt Tuning的总结
### 训练目标
Prompt Tuning方法为每一个输入文本假设一个固定前缀提示，该提示表由神经网络参数化，并在下游任务微调时进行更新，整个过程中预训练的大模型参数被冻结。

对于给定输入token，假设下游任务是文本生成，以期望输出的token为标签，模型的优化目标为：

Prompt Tuning方法在之前添加一段额外的token，这个由参数确定，模型优化目标变为：

在这个过程中，预训练模型参数保持固定，训练过程只更新的参数，以交叉熵为损失函数。

### 设计准则
为了达到一个良好的tuning效果，需要对Prompt进行设计，作者研究了针对T5模型的Span Courruption策略，Prompt token的数量，prompt初始化方案三个方面对于其提出方法的影响，所有实验均以SuperGLUE基准（在8个语言任务上进行综合评测的基准）进行评测：

#### Span Corruption策略分析
作者认为，T5使用的Span Corruption策略使得模型在训练和输出过程中始终存在哨兵标记，模型从来没有输出过真实完整的文本，这种模式可以通过Fine-tune很容易纠正过来，但是仅通过prompt可能难以消除哨兵的影响。

因此，作者设计了三种实验模式来验证他们的想法：

* Span Corruption策略：

使用原始T5模型训练好的参数，作为预训练模型，正常使用Prompt Tuning策略进行下游任务的微调。

* Span Corruption+ Sentinel策略：

使用原始T5模型训练好的参数，作为预训练模型，在进行下游任务的微调时，每一个文本输入的前面都添加了一个哨兵，使得输入更符合T5本身的输入形式。

* LM Adaptation策略：

对于按原始方法训练好的T5模型，额外使用LM（语言模型）优化目标进行少量步骤的Finetune，使模型从输出带哨兵的文本转换为输出真实文本，期望T5和 GPT一样生成真实的文本输出。（这是本实验的默认设置）。

![Alt text](image-2.png)

从上图中的图c和d可以发现，使用LM Adaption的策略确实效果要好很多，而且Adaption的时间越长，效果越好，不过只要模型参数足够大，用哪一种策略效果都差不多。
### Prompt的长度
上图a显示了使用不同长度的prompt对tuning性能的影响，发现prompt的长度越长，效果越好，但只要模型足够大，长度的影响也不大了。

### prompt初始化策略
作者设计了三种初始化方案，分别是Random Uniform，Sampled Vocab和Class Label。

Random Uniform方案从均匀分布中随机进行初始化；

Sampled Vocab方案从T5的语料库中选择最常见的5000个词汇，并从中选择词汇嵌入作为初始化；

Class Label方案则是将下游任务的标签对应的字符串表示的嵌入作为初始化，如果一个类有多个词，取词嵌入的平均表示作为一个prompt。假如标签数目不足，则从Sampled Vocab方案中继续采样补足。

最后发现，非随机初始化方法要显著好于随机初始化，而Class Label效果相对更好，当然，只要模型足够大，哪种初始化方法的差异就比较小了。

## 实验
### 性能对比
作者对比了他们的prompt tuning方法和直接对模型进行微调（单任务微调和多任务混合微调）以及GPT-3使用的Prompt Design方法之间的性能差异，发现他们的方法显著优于Prompt Design，并且在模型参数足够大的时候，性能和对整个模型进行微调的效果差不多。

![Alt text](image.png)

同时，比较了不同调优方法所需要优化的参数量，他们的方法参数量相对来说较少，并且显著低于直接微调的模型。

![Alt text](image-3.png)

###  Domain shift实验
所谓Domain shift其实就是跨域实验，即训练集与测试集的分布是不同的，来测试模型的泛化性能。

作者以SQuAD作为调优数据集，在调优完成后测试与训练集不同域的其他问答数据集的F1得分（准确性相关的评价指标），最后发现，使用prompt方法确实比直接微调模型具有更好的泛化效果，尤其是在域间差异越大时，泛化效果越好。

![](image-4.png)

### Prompt Ensembling
现有研究表明，为同一个任务使用不同初始化训练多个模型副本，以多个副本的共同决策结果作为最终输出可以提示模型表现水平。为了验证prompt tuning是否也具有类似的效果，作者为同一个任务训练了5个prompt模型，以投票表决的形式作为最终集成输出。作者发现，在SueprGLUE任务上集成prompt预测的结果优于平均预测结果，同时也优于单个最佳prompt的结果。

![](image-5.png)
## 可解释性
理想情况下，可解释的提示应由自然语言组成，该语言清楚地描述了手头的任务，明确地要求模型提供某些结果或操作，并易于理解为什么提示会从模型中引发此类行为。

由于提示调优在连续嵌入空间而不是离散标记空间中工作，因此解释提示变得更加困难。为了测试我们学习到的软提示的可解释性，我们从冻结模型的词汇表中计算出每个提示标记的最近邻。我们使用词汇嵌入向量和提示标记表示之间的余弦距离作为相似度指标。

我们观察到，对于给定的学习提示令牌，前 5 个最近邻形成紧密的语义簇。例如，我们看到词法相似的集群，如{技术/技术/技术/技术/技术}，以及更多样化但仍然密切相关的集群，如{完全/完全/完全/100%}。这些簇的性质表明，提示实际上是在学习“类似单词”的表示。我们发现，从嵌入空间抽取的随机向量不会显示这种语义聚类。

当使用“classlabel”策略初始化提示时，我们经常发现类标签在训练过程中仍然存在。具体而言，如果将提示令牌初始化为给定标签，则该标签在优化后通常位于学习令牌的最近邻标记之间。当使用“Random Uniform”或“Sampled Vocab”方法进行初始化时，类标签也可以在提示的最近邻中找到;但是，它们往往显示为多个提示令牌的邻居。这表明该模型正在学习将预期的输出类存储在提示中作为参考，并且将提示初始化为输出类使这更容易和更集中。

在检查较长的提示（例如大小 100 ）时，我们经常会发现几个具有相同最近邻的提示标记。 这表明提示中存在过剩的容量，或者提示表示中缺乏顺序结构使模型难以将信息定位到特定位置。

虽然学习的提示作为序列几乎没有可解释性，我们确实观察到科学、技术和工程等词的频率很高，因为在 BoolQ 数据集上训练的提示是最近邻，大约 20% 的问题属于“自然/科学”类别。虽然需要更多的研究，但这表明提示的一个作用可能是启动模型以解释特定领域或上下文（例如“科学”）中的输入。
## 结论
在本文中，我们证明了及时调优是一种使冻结的预训练语言模型适应下游任务的竞争技术。在流行的 SuperGLUE 基准测试中，其任务性能可与传统模型调优相媲美，随着模型大小的增加，差距逐渐消失。在零样本域转移中，我们发现及时调整可以改善泛化。这似乎表明，冻结通用语言理解参数并将下游学习限制在轻量级参数占用空间有助于避免过度拟合特定领域。

除了任务质量指标之外，我们还讨论了在存储和服务成本方面转向冻结预训练模型的吸引力。 此举既实现了高效的多任务服务，又实现了高效的高性能提示集成。展望未来，我们认为，将任务定义参数与一般语言建模参数区分开来是一个令人兴奋的步骤，它为新研究开辟了许多途径。
