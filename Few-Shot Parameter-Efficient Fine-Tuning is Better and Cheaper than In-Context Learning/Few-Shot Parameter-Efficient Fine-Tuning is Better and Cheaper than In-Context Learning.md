## finetune 范式的缺陷
语言模型在工业界落地困难的原因之一是它们的参数量较大，而Fine-tuning范式无法复用参数。Fine-tuning 范式针对每个任务都需要重新训练模型，一套参数的训练成本高，但不能在不同任务之间复用参数，性价比极低。
在企业中，往往数据来源丰富，数据分析需求复杂。比如基于一个语料库，可能有若干多个分类体系，针对每个分类体系，可能既有文本多分类，也有多标签分类，甚至是层级分类，总之任务多样。但由于这些数据来源可能是单一的（也就是说不同的任务享有同分布的数据，域是相同的），所以利用一套语言模型的参数，学习数据域中包含的实体，知识，关系，事件，标签结构等语义信息，再以此为基础，完成不同的任务需求是更合理的做法，也是实现起来更具有性价比的（总不能存几十套参数去部署到生产环境，针对每套参数微调也是一个极为消耗人力的过程）。

## ICL方法介绍
语言模型没有像GPT-3这么大的时候上面这套Fine-tuning做法虽然性价比极低，但还是有实现的可能。而现在的大模型很多出于成本和商业的考虑不再开源，与此同时，大模型具有的in-context learning能力为多任务少样本学习提供了一种解决方案。

![](https://pic4.zhimg.com/80/v2-36394e8a78258f0e7db490819edbdf8f_720w.webp)

这种方法的简单的说就是，在冻结大模型参数的情况下，在输入时，给定一些样本包含数据和标签，同时给一个待预测数据，由模型输出这条数据的预测值。这个过程中模型的参数不发生变化。因此在应用到下游任务时，不需要更新参数，可以扩展到各种各样的任务场景，为Language-Model-as-a-service提供了可能。
但这种模式使得，模型在每次推理过程中，都要处理一次prompts中的示例样本，这也是一种很大的计算消耗。并且in-context learning依然存在一些问题。研究指出，改变prompts中例子的顺序对最终预测效果的影响很大；还有的研究发现，prompts中的例子数据和标签在没有正确配对的情况下，对带预测数据的预测结果影响不是很大。这些现象说明in-context learning 背后的机制，以及如何使in-context learning效果更加鲁棒仍然有待研究。

## 本文方法介绍
本文主要对ICL和PEFT方法，在少样本场景下进行了严谨的实验对比，发现PEFT方法在取得很高精度的情况下，同时很大降低了计算消耗，可以作为替代ICL针对fine-tuning范式缺陷的一个解决方案。因此本文的目标是：**给出一套方案，使模型不需要在新的下游任务上手动调整模型结构，可以给出强大的少样本性能，并且在推理阶段允许批次内样本任务混合。** 创新点有两个：
1. 提出了一个新的PEFT方法(IA)3:Infused Adapters by Inhibiting and Amplifying Inner Activations. 通过学习向量与模型的激活曾相乘对模型参数进行加权。
2. 同时本文基于T0模型做了一套配方T-Few，在下游任务中不需要对任务进行额外模型调整，即可进行少样本学习。

![](https://pic2.zhimg.com/80/v2-a3616b99e2590d6cf4d1b989f7c7aa79_720w.webp)

### 创新点1：(IA)3
prompt tuning以及prefix tuning等方法可以满足下游多个任务同批次进行，精度不够，精度够的方法又不允许同批次多任务处理。因此需要开发一个新的PEFT方法。本文作者提出了Infused Adapter by Inhibiting and Amplifying Inner Activations, 从名字就可以看出，这种PEFT方法是对模型的一些激活层进行抑制或放大，也就是通过点乘一个向量的形式对模型的一部分参数进行加权，上图左侧展示了这些下游任务微调的小参数的添加位置，分别在attention机制中的Key向量和Value向量上，以及前馈神经网络的激活层后。有工作指出预训练这部分参数也可以进一步提高下游任务上的少样本以及零样本性能，因此本文也采纳了预训练的做法（精度64.6-->65.8）。

![](https://pic1.zhimg.com/80/v2-d14e1b6e35a42eb7e657ea316e66dabc_720w.webp)

## 创新点2：T-Few
PEFT方法的主旨是通过添加一小部分额外的参数对小样本进行微调，或微调模型本身一小部分的参数，以实现fine-tuning整个模型参数所达到的少样本性能。因此第一步是选择合适的预训练模型作为实践PEFT方法的backbone。本文在T0模型上取得了最佳性能。
由于本文使用“rank classification”评估模型（先对模型的预测标签按置信度排序，之心度最高的如果是true label，即为预测正确）。所以在模型训练过程，作者使用了不同loss：即上图右侧的语言模型损失$L_{LM}$, 负例似然损失$L_{UL}$, 长度归一化损失$L_{LN}$ ，损失函数详细介绍参考论文。语言模型本身的损失加上两个额外添加的损失函数后的性能变化结果如下:
![](https://pic3.zhimg.com/80/v2-898d5845623a27f413f3fe32db4c026e_720w.webp)

## 总结
尽管Few-shot in-context learning (ICL) 通过提供少量训练示例作为输入的一部分，使预训练的语言模型能够在没有任何基于梯度的训练的情况下执行以前看不见的任务。 但是ICL 会产生大量的计算成本，因为它涉及在每次进行预测时处理所有训练示例。

而本文基于作者团队先前的工作T0，修改了损失函数以适应少样本学习的情况，称为T-Few，无需针对特定任务进行调整或修改即可应用于新任务。并且引入了一种新的PEFT方法名为 (IA)3 ，通过学习向量来对激活层加权进行缩放，从而获得更强的性能，同时仅引入相对少量的新参数。

